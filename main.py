import os
import json
import logging
import time
import re
import requests
from datetime import datetime
from typing import List, Dict, Set
from dotenv import load_dotenv
from googleapiclient.discovery import build
import pandas as pd
from google.cloud import storage
from google.oauth2 import service_account

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv('YOUTUBE_API_KEY')
GCS_BUCKET_NAME = os.getenv('GCS_BUCKET_NAME')
GCS_CREDENTIALS_JSON = os.getenv('GCS_CREDENTIALS_JSON')
SLACK_WEBHOOK_URL = os.getenv('SLACK_WEBHOOK_URL')

def extract_email(description: str) -> str:
    """èª¬æ˜æ–‡ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŠ½å‡º"""
    if not description:
        return "å–å¾—å¤±æ•—"
    
    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    match = re.search(email_pattern, description)
    
    if match:
        return match.group(0)
    return "å–å¾—å¤±æ•—"

class YouTubeChannelCollector:
    def __init__(self):
        self.youtube = build('youtube', 'v3', developerKey=API_KEY)
        self.existing_channels = set()
        self.channels_df = None
        
        # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        if GCS_CREDENTIALS_JSON:
            try:
                credentials_info = json.loads(GCS_CREDENTIALS_JSON)
                credentials = service_account.Credentials.from_service_account_info(
                    credentials_info
                )
                self.storage_client = storage.Client(credentials=credentials)
                logger.info("GCSèªè¨¼æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            except json.JSONDecodeError as e:
                logger.error(f"GCSèªè¨¼æƒ…å ±ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™: {str(e)}")
                self.storage_client = None
            except Exception as e:
                logger.error(f"GCSèªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                self.storage_client = None
        else:
            self.storage_client = None
            logger.warning("GCSèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        self._load_existing_data()
        
    def _get_latest_csv_from_gcs(self) -> str:
        """GCSã‹ã‚‰æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        if not self.storage_client or not GCS_BUCKET_NAME:
            logger.warning("GCSèªè¨¼æƒ…å ±ã¾ãŸã¯ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é–‹å§‹ã—ã¾ã™ã€‚")
            return None
        
        try:
            bucket = self.storage_client.bucket(GCS_BUCKET_NAME)
            blobs = list(bucket.list_blobs(prefix='channels_'))
            
            if not blobs:
                logger.info("GCSã«æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é–‹å§‹ã—ã¾ã™ã€‚")
                return None
            
            # æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼‰
            latest_blob = max(blobs, key=lambda x: x.name)
            logger.info(f"GCSã‹ã‚‰æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—: {latest_blob.name}")
            
            # ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            local_filename = f"temp_{latest_blob.name}"
            latest_blob.download_to_filename(local_filename)
            logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {local_filename}")
            
            return local_filename
            
        except Exception as e:
            logger.error(f"GCSã‹ã‚‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return None
    
    def _load_existing_data(self):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        csv_filename = self._get_latest_csv_from_gcs()
        
        if csv_filename and os.path.exists(csv_filename):
            try:
                self.channels_df = pd.read_csv(csv_filename, encoding='utf-8')
                self.existing_channels = set(self.channels_df['channel_id'].tolist())
                logger.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(self.existing_channels)}")
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(csv_filename)
                logger.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {csv_filename}")
                
            except Exception as e:
                logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                self.channels_df = pd.DataFrame(columns=[
                    'channel_id', 'title', 'description', 'email', 
                    'subscriber_count', 'view_count', 'video_count', 'fetched_at'
                ])
                self.existing_channels = set()
        else:
            # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é–‹å§‹
            self.channels_df = pd.DataFrame(columns=[
                'channel_id', 'title', 'description', 'email', 
                'subscriber_count', 'view_count', 'video_count', 'fetched_at'
            ])
            self.existing_channels = set()
            logger.info("æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é–‹å§‹ã—ã¾ã™ã€‚")
    
    def _load_category_ids(self) -> List[Dict]:
        """ã‚«ãƒ†ã‚´ãƒªIDã®è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        with open('config/category_ids.json', 'r') as f:
            return json.load(f)['categories']
    
    def get_popular_videos(self, category_id: str) -> List[str]:
        """äººæ°—å‹•ç”»ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—"""
        try:
            channel_ids = set()
            next_page_token = None
            daily_limit = 10000  # YouTube Data APIã®1æ—¥ã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™
            total_quota = 0
            
            while True:
                request = self.youtube.videos().list(
                    part='snippet',
                    chart='mostPopular',
                    regionCode='JP',
                    videoCategoryId=category_id,
                    maxResults=50,
                    pageToken=next_page_token
                )
                response = request.execute()
                
                # ã‚¯ã‚©ãƒ¼ã‚¿æ¶ˆè²»é‡ã®è¨ˆç®—ï¼ˆvideos.listã¯1ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚ãŸã‚Š1ã‚¯ã‚©ãƒ¼ã‚¿ï¼‰
                total_quota += 1
                
                for item in response.get('items', []):
                    channel_id = item['snippet']['channelId']
                    if channel_id not in self.existing_channels:
                        channel_ids.add(channel_id)
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
                next_page_token = response.get('nextPageToken')
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã€ã¾ãŸã¯ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ãŸå ´åˆã¯çµ‚äº†
                if not next_page_token or total_quota >= daily_limit:
                    break
                
                # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
                time.sleep(1)
            
            logger.info(f"ã‚«ãƒ†ã‚´ãƒªID[{category_id}]ã§{len(channel_ids)}ä»¶ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            return list(channel_ids)
        except Exception as e:
            logger.error(f"å‹•ç”»ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªID[{category_id}]: {str(e)}")
            return []
    
    def get_channel_details(self, channel_ids: List[str]) -> List[Dict]:
        """ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        if not channel_ids:
            return []
        
        channels = []
        # ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’50å€‹ãšã¤ã®ãƒãƒƒãƒã«åˆ†å‰²
        batch_size = 50
        for i in range(0, len(channel_ids), batch_size):
            batch = channel_ids[i:i + batch_size]
            try:
                request = self.youtube.channels().list(
                    part='snippet,statistics',
                    id=','.join(batch),
                    maxResults=batch_size
                )
                response = request.execute()
                
                for item in response.get('items', []):
                    description = item['snippet'].get('description', '')
                    channel = {
                        'channel_id': item['id'],
                        'title': item['snippet']['title'],
                        'description': description,
                        'email': extract_email(description),
                        'subscriber_count': int(item['statistics'].get('subscriberCount', 0)),
                        'view_count': int(item['statistics'].get('viewCount', 0)),
                        'video_count': int(item['statistics'].get('videoCount', 0)),
                        'fetched_at': datetime.now()
                    }
                    channels.append(channel)
                
                # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒãƒƒãƒ {i//batch_size + 1}: {str(e)}")
                continue
        
        return channels
    
    def update_channels_data(self, new_channels: List[Dict]):
        """ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’DataFrameã«è¿½åŠ """
        if not new_channels:
            return
        
        # æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«ã‚’DataFrameã«è¿½åŠ 
        new_df = pd.DataFrame(new_channels)
        self.channels_df = pd.concat([self.channels_df, new_df], ignore_index=True)
        
        # æ—¢å­˜ãƒãƒ£ãƒ³ãƒãƒ«ã‚»ãƒƒãƒˆã‚’æ›´æ–°
        for channel in new_channels:
            self.existing_channels.add(channel['channel_id'])
        
        logger.info(f"{len(new_channels)}ä»¶ã®æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
    
    def export_to_csv_and_upload(self):
        """ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã€GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆç¾åœ¨ã®æ—¥æ™‚ã‚’å«ã‚ã‚‹ï¼‰
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            csv_filename = f'channels_{timestamp}.csv'
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            self.channels_df.to_csv(csv_filename, index=False, encoding='utf-8')
            logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {csv_filename}")
            
            # GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            if self.storage_client and GCS_BUCKET_NAME:
                bucket = self.storage_client.bucket(GCS_BUCKET_NAME)
                blob = bucket.blob(csv_filename)
                blob.upload_from_filename(csv_filename)
                logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: gs://{GCS_BUCKET_NAME}/{csv_filename}")
                
                # ãƒ­ãƒ¼ã‚«ãƒ«ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(csv_filename)
                logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {csv_filename}")
            else:
                logger.warning("GCSèªè¨¼æƒ…å ±ã¾ãŸã¯ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€GCSã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                
        except Exception as e:
            logger.error(f"CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¾ãŸã¯GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯æ®‹ã—ã¦ãŠã
            if os.path.exists(csv_filename):
                logger.info(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒã—ã¾ã™: {csv_filename}")
    
    def send_slack_notification(self, new_channels: List[Dict]):
        """Slackã«æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã‚’é€šçŸ¥"""
        if not SLACK_WEBHOOK_URL:
            logger.warning("Slack Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
        
        if not new_channels:
            logger.info("æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«ãŒãªã„ãŸã‚ã€Slacké€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
        
        try:
            message = f"ğŸ‰ YouTubeãƒãƒ£ãƒ³ãƒãƒ«åé›†ãƒãƒƒãƒå®Ÿè¡Œå®Œäº†ï¼\n\n"
            message += f"ğŸ“Š **å®Ÿè¡Œçµæœ**\n"
            message += f"â€¢ æ–°è¦å–å¾—ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(new_channels)}ä»¶\n"
            message += f"â€¢ å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            message += f"â€¢ ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(self.channels_df)}ä»¶\n\n"
            
            if new_channels:
                message += f"ğŸ“‹ **æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«ä¸€è¦§**\n"
                
                for i, channel in enumerate(new_channels[:10], 1):  # æœ€å¤§10ä»¶ã¾ã§è¡¨ç¤º
                    message += f"{i}. **{channel['title']}**\n"
                    message += f"   â€¢ ãƒãƒ£ãƒ³ãƒãƒ«ID: `{channel['channel_id']}`\n"
                    message += f"   â€¢ ãƒ¡ãƒ¼ãƒ«: {channel['email']}\n"
                    message += f"   â€¢ ç™»éŒ²è€…æ•°: {channel['subscriber_count']:,}\n"
                    message += f"   â€¢ ç·å†ç”Ÿå›æ•°: {channel['view_count']:,}\n"
                    message += f"   â€¢ å‹•ç”»æ•°: {channel['video_count']:,}\n\n"
                
                if len(new_channels) > 10:
                    message += f"... ä»– {len(new_channels) - 10}ä»¶ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚‚å–å¾—ã•ã‚Œã¾ã—ãŸã€‚\n\n"
            
            message += f"ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚"
            
            payload = {"text": message}
            response = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=10)
            
            if response.status_code == 200:
                logger.info("Slacké€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
            else:
                logger.error(f"Slacké€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Slacké€šçŸ¥ã®é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ"""
        logger.info(f"ãƒãƒƒãƒå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚æ—¢å­˜ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(self.existing_channels)}")
        
        # ã‚«ãƒ†ã‚´ãƒªIDã®èª­ã¿è¾¼ã¿
        categories = self._load_category_ids()
        total_new_channels = 0
        all_new_channels = []
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«å‡¦ç†
        for category in categories:
            logger.info(f"å‡¦ç†ä¸­ ã‚«ãƒ†ã‚´ãƒª: {category['name']} (ID: {category['id']})")
            
            # äººæ°—å‹•ç”»ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—
            channel_ids = self.get_popular_videos(category['id'])
            
            if channel_ids:
                # ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°ã‚’å–å¾—
                channels: List[Dict] = self.get_channel_details(channel_ids)
                
                # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
                self.update_channels_data(channels)
                all_new_channels.extend(channels)
                
                new_channels_count = len(channels)
                total_new_channels += new_channels_count
                logger.info(f"Fetched {new_channels_count} new channels in category {category['name']}")
            
            # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            time.sleep(1)
        
        logger.info(f"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚åˆè¨ˆå–å¾—ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {total_new_channels}")
        
        # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¨GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
        logger.info(f"CSVå‡ºåŠ›+GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        self.export_to_csv_and_upload()
        logger.info(f"CSVå‡ºåŠ›+GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        
        # Slacké€šçŸ¥
        logger.info(f"Slacké€šçŸ¥å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(all_new_channels)}")
        self.send_slack_notification(all_new_channels)
        
        logger.info(f"ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚æ–°è¦ãƒãƒ£ãƒ³ãƒãƒ«: {len(all_new_channels)}ä»¶, ç·ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(self.channels_df)}ä»¶")

if __name__ == '__main__':
    if not API_KEY:
        raise ValueError("YouTube APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    if not GCS_CREDENTIALS_JSON:
        raise ValueError("GCSèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    collector = YouTubeChannelCollector()
    collector.run() 